{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from nltk.corpus import  stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import regex\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 5)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('tweet final.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Author</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>http://twitpic.com/2y1zl - Awww, that's a bum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 1                     Date/Time           Author  \\\n",
       "0         NaN         NaN  Mon Apr 06 22:19:45 PDT 2009  _TheSpecialOne_   \n",
       "1         NaN         NaN  Mon Apr 06 22:19:49 PDT 2009    scotthamilton   \n",
       "2         NaN         NaN  Mon Apr 06 22:19:53 PDT 2009         mattycus   \n",
       "3         NaN         NaN  Mon Apr 06 22:19:57 PDT 2009          ElleCTF   \n",
       "4         NaN         NaN  Mon Apr 06 22:19:57 PDT 2009           Karoli   \n",
       "\n",
       "                                               Topic  \n",
       "0   http://twitpic.com/2y1zl - Awww, that's a bum...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 1    1.0\n",
       "Unnamed: 0    1.0\n",
       "Topic         0.0\n",
       "Author        0.0\n",
       "Date/Time     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    float64\n",
       "Unnamed: 1    float64\n",
       "Date/Time      object\n",
       "Author         object\n",
       "Topic          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    200\n",
       "Unnamed: 1    200\n",
       "Date/Time       0\n",
       "Author          0\n",
       "Topic           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df:\n",
    "    if type(df[col])=='object':\n",
    "        df[col]=df[col].fillna(value='unknown')\n",
    "    else:\n",
    "        df[col] =df[col].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 1', 'Date/Time', 'Author', 'Topic'], dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0','Unnamed: 1'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Author</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>http://twitpic.com/2y1zl - Awww, that's a bum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date/Time           Author  \\\n",
       "0  Mon Apr 06 22:19:45 PDT 2009  _TheSpecialOne_   \n",
       "1  Mon Apr 06 22:19:49 PDT 2009    scotthamilton   \n",
       "2  Mon Apr 06 22:19:53 PDT 2009         mattycus   \n",
       "3  Mon Apr 06 22:19:57 PDT 2009          ElleCTF   \n",
       "4  Mon Apr 06 22:19:57 PDT 2009           Karoli   \n",
       "\n",
       "                                               Topic  \n",
       "0   http://twitpic.com/2y1zl - Awww, that's a bum...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Author</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>httptwitpiccom2y1zl  Awww thats a bummer  You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he cant update his Facebook by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>Kenichan I dived many times for the ball Manag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>nationwideclass no its not behaving at all im ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date/Time           Author  \\\n",
       "0  Mon Apr 06 22:19:45 PDT 2009  _TheSpecialOne_   \n",
       "1  Mon Apr 06 22:19:49 PDT 2009    scotthamilton   \n",
       "2  Mon Apr 06 22:19:53 PDT 2009         mattycus   \n",
       "3  Mon Apr 06 22:19:57 PDT 2009          ElleCTF   \n",
       "4  Mon Apr 06 22:19:57 PDT 2009           Karoli   \n",
       "\n",
       "                                               Topic  \n",
       "0   httptwitpiccom2y1zl  Awww thats a bummer  You...  \n",
       "1  is upset that he cant update his Facebook by t...  \n",
       "2  Kenichan I dived many times for the ball Manag...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  nationwideclass no its not behaving at all im ...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove_punct\n",
    "df['Topic'] = df['Topic'].str.replace('[^\\w\\s]','')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=RegexpTokenizer(r'\\S+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [httptwitpiccom2y1zl, awww, thats, a, bummer, ...\n",
       "1    [is, upset, that, he, cant, update, his, faceb...\n",
       "2    [kenichan, i, dived, many, times, for, the, ba...\n",
       "3    [my, whole, body, feels, itchy, and, like, its...\n",
       "4    [nationwideclass, no, its, not, behaving, at, ...\n",
       "5                    [kwesidei, not, the, whole, crew]\n",
       "6                                       [need, a, hug]\n",
       "7    [loltrish, hey, long, time, no, see, yes, rain...\n",
       "8             [tatiana_k, nope, they, didnt, have, it]\n",
       "9                           [twittera, que, me, muera]\n",
       "Name: Topic, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Topic']=df['Topic'].apply(lambda x:tokenizer.tokenize(x.lower()))\n",
    "df['Topic'].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Author</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>[httptwitpiccom2y1zl, awww, thats, bummer, sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>[upset, cant, update, facebook, texting, might...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>[kenichan, dived, many, times, ball, managed, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>[nationwideclass, behaving, im, mad, cant, see]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>[kwesidei, whole, crew]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>mybirch</td>\n",
       "      <td>[need, hug]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>coZZ</td>\n",
       "      <td>[loltrish, hey, long, time, see, yes, rains, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mon Apr 06 22:20:05 PDT 2009</td>\n",
       "      <td>2Hood4Hollywood</td>\n",
       "      <td>[tatiana_k, nope, didnt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mon Apr 06 22:20:09 PDT 2009</td>\n",
       "      <td>mimismo</td>\n",
       "      <td>[twittera, que, muera]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date/Time           Author  \\\n",
       "0  Mon Apr 06 22:19:45 PDT 2009  _TheSpecialOne_   \n",
       "1  Mon Apr 06 22:19:49 PDT 2009    scotthamilton   \n",
       "2  Mon Apr 06 22:19:53 PDT 2009         mattycus   \n",
       "3  Mon Apr 06 22:19:57 PDT 2009          ElleCTF   \n",
       "4  Mon Apr 06 22:19:57 PDT 2009           Karoli   \n",
       "5  Mon Apr 06 22:20:00 PDT 2009         joy_wolf   \n",
       "6  Mon Apr 06 22:20:03 PDT 2009          mybirch   \n",
       "7  Mon Apr 06 22:20:03 PDT 2009             coZZ   \n",
       "8  Mon Apr 06 22:20:05 PDT 2009  2Hood4Hollywood   \n",
       "9  Mon Apr 06 22:20:09 PDT 2009          mimismo   \n",
       "\n",
       "                                               Topic  \n",
       "0  [httptwitpiccom2y1zl, awww, thats, bummer, sho...  \n",
       "1  [upset, cant, update, facebook, texting, might...  \n",
       "2  [kenichan, dived, many, times, ball, managed, ...  \n",
       "3            [whole, body, feels, itchy, like, fire]  \n",
       "4    [nationwideclass, behaving, im, mad, cant, see]  \n",
       "5                            [kwesidei, whole, crew]  \n",
       "6                                        [need, hug]  \n",
       "7  [loltrish, hey, long, time, see, yes, rains, b...  \n",
       "8                           [tatiana_k, nope, didnt]  \n",
       "9                             [twittera, que, muera]  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove_stopwords\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(Topic):\n",
    "    Topic = [word for word in Topic if word not in stopword]\n",
    "    return Topic\n",
    "    \n",
    "df['Topic'] = df['Topic'].apply(lambda x: remove_stopwords(x))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Author</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>[httptwitpiccom2y1zl, awww, that, bummer, shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>[upset, cant, updat, facebook, text, might, cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>[kenichan, dive, mani, time, ball, manag, save...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>[whole, bodi, feel, itchi, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>[nationwideclass, behav, im, mad, cant, see]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date/Time           Author  \\\n",
       "0  Mon Apr 06 22:19:45 PDT 2009  _TheSpecialOne_   \n",
       "1  Mon Apr 06 22:19:49 PDT 2009    scotthamilton   \n",
       "2  Mon Apr 06 22:19:53 PDT 2009         mattycus   \n",
       "3  Mon Apr 06 22:19:57 PDT 2009          ElleCTF   \n",
       "4  Mon Apr 06 22:19:57 PDT 2009           Karoli   \n",
       "\n",
       "                                               Topic  \n",
       "0  [httptwitpiccom2y1zl, awww, that, bummer, shou...  \n",
       "1  [upset, cant, updat, facebook, text, might, cr...  \n",
       "2  [kenichan, dive, mani, time, ball, manag, save...  \n",
       "3             [whole, bodi, feel, itchi, like, fire]  \n",
       "4       [nationwideclass, behav, im, mad, cant, see]  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming and Lammitization\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def stemming(Topic):\n",
    "    Topic = [ps.stem(word) for word in Topic]\n",
    "    return Topic\n",
    "\n",
    "df['Topic'] = df['Topic'].apply(lambda x: stemming(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#mport time\n",
    "#from sklearn.externals import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in e:\\anaconda\\lib\\site-packages (0.23.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in e:\\anaconda\\lib\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in e:\\anaconda\\lib\\site-packages (from scikit-learn) (1.18.5)\n",
      "Requirement already satisfied: joblib>=0.11 in e:\\anaconda\\lib\\site-packages (from scikit-learn) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\anaconda\\lib\\site-packages (from scikit-learn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Date/Time']]\n",
    "y = df['Topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Mon Apr 06 22:28:32 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Mon Apr 06 22:28:11 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Mon Apr 06 22:23:28 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Mon Apr 06 22:26:33 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Mon Apr 06 22:23:03 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Mon Apr 06 22:27:25 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Mon Apr 06 22:26:10 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Mon Apr 06 22:22:47 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Mon Apr 06 22:26:22 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Mon Apr 06 22:21:56 PDT 2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date/Time\n",
       "149  Mon Apr 06 22:28:32 PDT 2009\n",
       "138  Mon Apr 06 22:28:11 PDT 2009\n",
       "67   Mon Apr 06 22:23:28 PDT 2009\n",
       "100  Mon Apr 06 22:26:33 PDT 2009\n",
       "62   Mon Apr 06 22:23:03 PDT 2009\n",
       "..                            ...\n",
       "122  Mon Apr 06 22:27:25 PDT 2009\n",
       "90   Mon Apr 06 22:26:10 PDT 2009\n",
       "57   Mon Apr 06 22:22:47 PDT 2009\n",
       "94   Mon Apr 06 22:26:22 PDT 2009\n",
       "44   Mon Apr 06 22:21:56 PDT 2009\n",
       "\n",
       "[140 rows x 1 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mon Apr 06 22:20:16 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Mon Apr 06 22:26:10 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Mon Apr 06 22:31:29 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Mon Apr 06 22:25:54 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Mon Apr 06 22:32:51 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Mon Apr 06 22:26:27 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Mon Apr 06 22:26:48 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Mon Apr 06 22:28:18 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Mon Apr 06 22:25:54 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Mon Apr 06 22:32:40 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mon Apr 06 22:20:17 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Mon Apr 06 22:26:54 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mon Apr 06 22:20:37 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Mon Apr 06 22:27:34 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Mon Apr 06 22:25:56 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Mon Apr 06 22:22:24 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Mon Apr 06 22:28:48 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Mon Apr 06 22:25:49 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Mon Apr 06 22:28:15 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Mon Apr 06 22:27:18 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Mon Apr 06 22:31:35 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Mon Apr 06 22:21:21 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Mon Apr 06 22:31:37 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Mon Apr 06 22:28:24 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Mon Apr 06 22:21:07 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Mon Apr 06 22:21:09 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Mon Apr 06 22:23:43 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Mon Apr 06 22:32:22 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mon Apr 06 22:20:20 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Mon Apr 06 22:21:39 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Mon Apr 06 22:23:23 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Mon Apr 06 22:28:03 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Mon Apr 06 22:30:56 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Mon Apr 06 22:23:08 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Mon Apr 06 22:23:30 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Mon Apr 06 22:28:33 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Mon Apr 06 22:32:35 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Mon Apr 06 22:27:02 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Mon Apr 06 22:28:09 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Mon Apr 06 22:23:43 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Mon Apr 06 22:32:28 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Mon Apr 06 22:28:23 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Mon Apr 06 22:28:26 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Mon Apr 06 22:25:45 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Mon Apr 06 22:27:16 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Mon Apr 06 22:22:13 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Mon Apr 06 22:21:11 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Mon Apr 06 22:21:30 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Mon Apr 06 22:22:25 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Mon Apr 06 22:32:20 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Mon Apr 06 22:22:32 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Mon Apr 06 22:22:49 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Mon Apr 06 22:23:28 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Mon Apr 06 22:28:26 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Mon Apr 06 22:31:09 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Mon Apr 06 22:32:02 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Mon Apr 06 22:26:29 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Mon Apr 06 22:26:14 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Mon Apr 06 22:26:06 PDT 2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date/Time\n",
       "10   Mon Apr 06 22:20:16 PDT 2009\n",
       "89   Mon Apr 06 22:26:10 PDT 2009\n",
       "167  Mon Apr 06 22:31:29 PDT 2009\n",
       "83   Mon Apr 06 22:25:54 PDT 2009\n",
       "197  Mon Apr 06 22:32:51 PDT 2009\n",
       "95   Mon Apr 06 22:26:27 PDT 2009\n",
       "106  Mon Apr 06 22:26:48 PDT 2009\n",
       "141  Mon Apr 06 22:28:18 PDT 2009\n",
       "84   Mon Apr 06 22:25:54 PDT 2009\n",
       "195  Mon Apr 06 22:32:40 PDT 2009\n",
       "11   Mon Apr 06 22:20:17 PDT 2009\n",
       "6    Mon Apr 06 22:20:03 PDT 2009\n",
       "110  Mon Apr 06 22:26:54 PDT 2009\n",
       "20   Mon Apr 06 22:20:37 PDT 2009\n",
       "124  Mon Apr 06 22:27:34 PDT 2009\n",
       "85   Mon Apr 06 22:25:56 PDT 2009\n",
       "51   Mon Apr 06 22:22:24 PDT 2009\n",
       "154  Mon Apr 06 22:28:48 PDT 2009\n",
       "79   Mon Apr 06 22:25:49 PDT 2009\n",
       "140  Mon Apr 06 22:28:15 PDT 2009\n",
       "119  Mon Apr 06 22:27:18 PDT 2009\n",
       "170  Mon Apr 06 22:31:35 PDT 2009\n",
       "34   Mon Apr 06 22:21:21 PDT 2009\n",
       "169  Mon Apr 06 22:31:37 PDT 2009\n",
       "145  Mon Apr 06 22:28:24 PDT 2009\n",
       "30   Mon Apr 06 22:21:07 PDT 2009\n",
       "32   Mon Apr 06 22:21:09 PDT 2009\n",
       "73   Mon Apr 06 22:23:43 PDT 2009\n",
       "186  Mon Apr 06 22:32:22 PDT 2009\n",
       "14   Mon Apr 06 22:20:20 PDT 2009\n",
       "40   Mon Apr 06 22:21:39 PDT 2009\n",
       "66   Mon Apr 06 22:23:23 PDT 2009\n",
       "133  Mon Apr 06 22:28:03 PDT 2009\n",
       "162  Mon Apr 06 22:30:56 PDT 2009\n",
       "63   Mon Apr 06 22:23:08 PDT 2009\n",
       "69   Mon Apr 06 22:23:30 PDT 2009\n",
       "148  Mon Apr 06 22:28:33 PDT 2009\n",
       "193  Mon Apr 06 22:32:35 PDT 2009\n",
       "114  Mon Apr 06 22:27:02 PDT 2009\n",
       "137  Mon Apr 06 22:28:09 PDT 2009\n",
       "72   Mon Apr 06 22:23:43 PDT 2009\n",
       "189  Mon Apr 06 22:32:28 PDT 2009\n",
       "143  Mon Apr 06 22:28:23 PDT 2009\n",
       "146  Mon Apr 06 22:28:26 PDT 2009\n",
       "77   Mon Apr 06 22:25:45 PDT 2009\n",
       "118  Mon Apr 06 22:27:16 PDT 2009\n",
       "48   Mon Apr 06 22:22:13 PDT 2009\n",
       "33   Mon Apr 06 22:21:11 PDT 2009\n",
       "37   Mon Apr 06 22:21:30 PDT 2009\n",
       "49   Mon Apr 06 22:22:25 PDT 2009\n",
       "185  Mon Apr 06 22:32:20 PDT 2009\n",
       "54   Mon Apr 06 22:22:32 PDT 2009\n",
       "58   Mon Apr 06 22:22:49 PDT 2009\n",
       "68   Mon Apr 06 22:23:28 PDT 2009\n",
       "147  Mon Apr 06 22:28:26 PDT 2009\n",
       "164  Mon Apr 06 22:31:09 PDT 2009\n",
       "181  Mon Apr 06 22:32:02 PDT 2009\n",
       "98   Mon Apr 06 22:26:29 PDT 2009\n",
       "91   Mon Apr 06 22:26:14 PDT 2009\n",
       "87   Mon Apr 06 22:26:06 PDT 2009"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149    [rumblepurr, lol, wish, understood, daylight, ...\n",
       "138    [india, miss, 100th, test, victori, n, 10th, c...\n",
       "67     [mo, job, money, hell, min, wage, 4, fn, clam,...\n",
       "100    [bodi, miss, northern, calif, girl, found, pol...\n",
       "62                                          [life, cool]\n",
       "                             ...                        \n",
       "122    [know, life, flip, upsid, thought, head, ramen...\n",
       "90     [hollywoodheat, paid, attent, cover, photoshop...\n",
       "57     [sad, feel, dalla, go, show, gotta, say, thoug...\n",
       "94     [makeherfam, hmm, u, realli, enjoy, problem, c...\n",
       "44     [fall, asleep, heard, traci, girl, bodi, found...\n",
       "Name: Topic, Length: 140, dtype: object"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10                    [spring, break, plain, citi, snow]\n",
       "89     [januarycrimson, sorri, babe, fam, annoy, than...\n",
       "167    [go, school, soon, cant, find, anyth, wear, go...\n",
       "83                                  [markhardy1974, itm]\n",
       "197                                   [go, sleep, tonit]\n",
       "95     [strider, sick, littl, puppi, httpappsfacebook...\n",
       "106    [emili, glad, mommi, done, train, new, job, mi...\n",
       "141                 [ozesteph1992, shame, hear, stephan]\n",
       "84              [damn, dont, chalk, chalkboard, useless]\n",
       "195           [didnt, get, shit, done, today, im, screw]\n",
       "11                                        [repierc, ear]\n",
       "6                                            [need, hug]\n",
       "110                                     [lay, bed, voic]\n",
       "20              [alydesign, day, didnt, get, much, done]\n",
       "124    [late, night, snack, glass, oj, bc, im, quotdo...\n",
       "85     [blast, getti, villa, hate, she, sore, throat,...\n",
       "51     [localtweep, wow, ton, repli, may, unfollow, s...\n",
       "154    [jonathanchard, calori, wise, wish, junk, food...\n",
       "79     [wonder, someon, u, like, much, make, unhappi,...\n",
       "140                                     [sadli, go, bed]\n",
       "119    [erre_sc, aaw, miss, ya, im, leav, bh, tomorro...\n",
       "170            [crazi, wind, today, bird, httpffim1xtti]\n",
       "34            [humpninja, cri, asian, eye, sleep, night]\n",
       "169    [naughtyhaughti, page, sooooo, long, got, dele...\n",
       "145    [twista202, still, havent, read, 9thamp10th, p...\n",
       "30           [some1, hack, account, aim, make, new, one]\n",
       "32     [thought, sleep, option, tomorrow, realiz, eva...\n",
       "73     [gym, attir, today, puma, singlet, adida, shor...\n",
       "186    [mani, channel, yet, bore, lazi, day, may, fin...\n",
       "14     [smarrison, wouldv, first, didnt, gun, realli,...\n",
       "40     [realli, dont, feel, like, get, today, got, st...\n",
       "66                        [damm, back, school, tomorrow]\n",
       "133                                     [almost, bedtim]\n",
       "162                                          [feel, bad]\n",
       "63     [sadli, though, ive, never, gotten, experi, po...\n",
       "69     [lt_algonquin, agre, saw, failwhal, allllll, d...\n",
       "148             [go, sleep, hope, tomorrow, better, day]\n",
       "193    [goodlaura, rees, die, ttsc, season, final, ne...\n",
       "114                                [salancast, hope, ok]\n",
       "137    [bridgetsbeach, thank, let, peopl, know, im, s...\n",
       "72     [realli, hate, peopl, diss, band, trace, clear...\n",
       "189    [opp, said, still, got, one, day, remain, prob...\n",
       "143    [intend, finish, edit, 536page, novel, manuscr...\n",
       "146                                   [nokia, 1110, die]\n",
       "77                              [new, csi, tonight, fml]\n",
       "118             [hang, crooner, wanna, sing, cant, suck]\n",
       "48                     [strang, sad, lilo, samro, break]\n",
       "33                      [julieebabi, awe, love, 1, miss]\n",
       "37     [missxu, sorri, bed, time, came, gmt1, httpisg...\n",
       "49           [tea, oh, im, sorri, didnt, think, retweet]\n",
       "185                             [watch, hill, make, sad]\n",
       "54                                           [need, hug]\n",
       "58                              [ugh92, degre, tomorrow]\n",
       "68                          [katortiz, forev, see, soon]\n",
       "147    [mom, might, breast, cancer, wont, find, anyth...\n",
       "164    [pinkserendip, ye, sprint, 4g, baltimor, chica...\n",
       "181         [check, mug, httpwwwerikaobscurablogspotcom]\n",
       "98                   [stark, dont, follow, either, work]\n",
       "91                      [wednesday, bday, dont, know, 2]\n",
       "87     [tummi, hurt, wonder, hypnosi, anyth, work, ge...\n",
       "Name: Topic, dtype: object"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Mon Apr 06 22:28:32 PDT 2009'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-146-0f4a7eb4b158>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \"\"\"\n\u001b[1;32m--> 615\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_class_log_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_prior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    797\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Mon Apr 06 22:28:32 PDT 2009'"
     ]
    }
   ],
   "source": [
    "#Predict the sentiment\n",
    "\n",
    "def predict(Topic,classifier):\n",
    "    \n",
    "    tweet_processed = stem(preprocessTweets(tweet))\n",
    "             \n",
    "    if ( ('__positive__') in (tweet_processed)):\n",
    "         sentiment  = 1\n",
    "         return sentiment\n",
    "        \n",
    "    elif ( ('__negative__') in (tweet_processed)):\n",
    "         sentiment  = 0\n",
    "         return sentiment       \n",
    "    else:\n",
    "        \n",
    "        X =  [tweet_processed]\n",
    "        sentiment = classifier.predict(X)\n",
    "        return (sentiment[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
